{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5d1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç Analyzing Parquet File Issues\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "   Total samples: 100\n",
      "   Params per sample: 60\n",
      "   Input features: 10\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "BASE_DIR = Path(\"..\")\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "PYBAMM_DIR = DATA_DIR / \"final_pybamm_output\"\n",
    "OUTPUT_PARAM_DIR = DATA_DIR / \"output_parameter_sweep\"\n",
    "CONFIG_DIR = BASE_DIR / \"configs\"\n",
    "\n",
    "with open(CONFIG_DIR / \"optimise_config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "TOTAL_SAMPLES = config[\"data\"][\"total_samples\"]\n",
    "PARAMS_PER_SAMPLE = config[\"data\"][\"params_per_sample\"]\n",
    "INPUT_FEATURES = config[\"data\"][\"input_features\"]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç Analyzing Parquet File Issues\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"   Total samples: {TOTAL_SAMPLES}\")\n",
    "print(f\"   Params per sample: {PARAMS_PER_SAMPLE}\")\n",
    "print(f\"   Input features: {len(INPUT_FEATURES)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a690dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading tau_results.csv...\n",
      "‚úì Loaded 100 rows\n",
      "\n",
      "Columns: ['id', 'filename', 'porosity_measured', 'tau_factor', 'D_eff', 'error']\n",
      "\n",
      "Sample IDs in tau_results: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19)]...\n",
      "\n",
      "‚úÖ All 100 samples present in tau_results\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìÇ Loading tau_results.csv...\")\n",
    "tau_results = pd.read_csv(OUTPUT_PARAM_DIR / \"taufactor_results.csv\")\n",
    "\n",
    "print(f\"‚úì Loaded {len(tau_results)} rows\")\n",
    "print(f\"\\nColumns: {list(tau_results.columns)}\")\n",
    "print(f\"\\nSample IDs in tau_results: {sorted(tau_results['id'].unique())[:20]}...\")\n",
    "\n",
    "expected_samples = set(range(TOTAL_SAMPLES))\n",
    "actual_samples = set(tau_results[\"id\"].unique())\n",
    "missing_in_tau = expected_samples - actual_samples\n",
    "\n",
    "if missing_in_tau:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(missing_in_tau)} samples missing from tau_results:\")\n",
    "    print(f\"   {sorted(missing_in_tau)}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All {TOTAL_SAMPLES} samples present in tau_results\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0fc200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Analyzing all sample+param combinations...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Analyzing all sample+param combinations...\")\n",
    "\n",
    "failures = {\n",
    "    \"tau_missing\": [],\n",
    "    \"parquet_missing\": [],\n",
    "    \"param_id_missing\": [],\n",
    "    \"input_features_missing\": [],\n",
    "    \"bruggeman_missing\": [],\n",
    "    \"capacity_missing\": [],\n",
    "    \"success\": [],\n",
    "}\n",
    "\n",
    "detailed_failures = []\n",
    "\n",
    "for sample_id in range(TOTAL_SAMPLES):\n",
    "    tau_rows = tau_results[tau_results[\"id\"] == sample_id]\n",
    "    has_tau = len(tau_rows) > 0\n",
    "\n",
    "    parquet_file = PYBAMM_DIR / f\"results_rank_{sample_id}.parquet\"\n",
    "    has_parquet = parquet_file.exists()\n",
    "\n",
    "    if not has_parquet:\n",
    "        for param_id in range(PARAMS_PER_SAMPLE):\n",
    "            failures[\"parquet_missing\"].append((sample_id, param_id))\n",
    "        continue\n",
    "\n",
    "    parquet_df = pd.read_parquet(parquet_file)\n",
    "\n",
    "    for param_id in range(PARAMS_PER_SAMPLE):\n",
    "        param_rows = parquet_df[parquet_df[\"param_id\"] == param_id]\n",
    "\n",
    "        if len(param_rows) == 0:\n",
    "            failures[\"param_id_missing\"].append((sample_id, param_id))\n",
    "            detailed_failures.append(\n",
    "                {\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"param_id\": param_id,\n",
    "                    \"reason\": \"param_id not found in parquet\",\n",
    "                    \"details\": f\"Available param_ids: {sorted(parquet_df['param_id'].unique())}\",\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if not has_tau:\n",
    "            failures[\"tau_missing\"].append((sample_id, param_id))\n",
    "            detailed_failures.append(\n",
    "                {\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"param_id\": param_id,\n",
    "                    \"reason\": \"sample_id not in tau_results\",\n",
    "                    \"details\": \"\",\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        param_row = param_rows.iloc[0]\n",
    "\n",
    "        missing_inputs = [\n",
    "            feat\n",
    "            for feat in INPUT_FEATURES\n",
    "            if feat not in param_row.index or pd.isna(param_row[feat])\n",
    "        ]\n",
    "\n",
    "        if missing_inputs:\n",
    "            failures[\"input_features_missing\"].append((sample_id, param_id))\n",
    "            detailed_failures.append(\n",
    "                {\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"param_id\": param_id,\n",
    "                    \"reason\": \"missing input features\",\n",
    "                    \"details\": (\n",
    "                        f\"Missing: {missing_inputs[:3]}...\"\n",
    "                        if len(missing_inputs) > 3\n",
    "                        else f\"Missing: {missing_inputs}\"\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if \"bruggeman_derived\" not in param_row.index or pd.isna(\n",
    "            param_row[\"bruggeman_derived\"]\n",
    "        ):\n",
    "            failures[\"bruggeman_missing\"].append((sample_id, param_id))\n",
    "            detailed_failures.append(\n",
    "                {\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"param_id\": param_id,\n",
    "                    \"reason\": \"bruggeman_derived missing or NaN\",\n",
    "                    \"details\": f\"Value: {param_row.get('bruggeman_derived', 'NOT FOUND')}\",\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if \"capacity_trend_ah\" not in param_row.index:\n",
    "            failures[\"capacity_missing\"].append((sample_id, param_id))\n",
    "            detailed_failures.append(\n",
    "                {\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"param_id\": param_id,\n",
    "                    \"reason\": \"capacity_trend_ah missing\",\n",
    "                    \"details\": f\"Available columns: {list(param_row.index)[:10]}...\",\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        failures[\"success\"].append((sample_id, param_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114e848c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä FAILURE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total expected: 6000\n",
      "Successful: 6000\n",
      "Failed: 0\n",
      "\n",
      "Failure breakdown:\n",
      "   Tau results missing: 0\n",
      "   Parquet file missing: 0\n",
      "   Param ID not found: 0\n",
      "   Input features missing: 0\n",
      "   Bruggeman missing: 0\n",
      "   Capacity trend missing: 0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä FAILURE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_expected = TOTAL_SAMPLES * PARAMS_PER_SAMPLE\n",
    "\n",
    "print(f\"\\nTotal expected: {total_expected}\")\n",
    "print(f\"Successful: {len(failures['success'])}\")\n",
    "print(f\"Failed: {total_expected - len(failures['success'])}\")\n",
    "\n",
    "print(\"\\nFailure breakdown:\")\n",
    "print(f\"   Tau results missing: {len(failures['tau_missing'])}\")\n",
    "print(f\"   Parquet file missing: {len(failures['parquet_missing'])}\")\n",
    "print(f\"   Param ID not found: {len(failures['param_id_missing'])}\")\n",
    "print(f\"   Input features missing: {len(failures['input_features_missing'])}\")\n",
    "print(f\"   Bruggeman missing: {len(failures['bruggeman_missing'])}\")\n",
    "print(f\"   Capacity trend missing: {len(failures['capacity_missing'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04792f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç DETAILED FAILURE EXAMPLES (first 20)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ No failures detected!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç DETAILED FAILURE EXAMPLES (first 20)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_failures = pd.DataFrame(detailed_failures)\n",
    "\n",
    "if len(df_failures) > 0:\n",
    "    print(f\"\\nTotal failures: {len(df_failures)}\")\n",
    "\n",
    "    print(\"\\nFailures by reason:\")\n",
    "    for reason, count in df_failures[\"reason\"].value_counts().items():\n",
    "        print(f\"   {reason}: {count}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"First 20 failures:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for _, row in df_failures.head(20).iterrows():\n",
    "        print(f\"\\nSample {row['sample_id']:3d}, Param {row['param_id']:2d}:\")\n",
    "        print(f\"   Reason: {row['reason']}\")\n",
    "        if row[\"details\"]:\n",
    "            print(f\"   Details: {row['details']}\")\n",
    "\n",
    "    output_file = BASE_DIR / \"data\" / \"parquet_failures.csv\"\n",
    "    df_failures.to_csv(output_file, index=False)\n",
    "    print(f\"\\nüíæ Full failure report saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No failures detected!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0262e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(detailed_failures) > 0:\n",
    "    failed_sample = detailed_failures[0]\n",
    "    SAMPLE_ID = failed_sample[\"sample_id\"]\n",
    "    PARAM_ID = failed_sample[\"param_id\"]\n",
    "\n",
    "    print(f\"\\nüîç DETAILED INSPECTION: Sample {SAMPLE_ID}, Param {PARAM_ID}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\n1. TAU RESULTS:\")\n",
    "    tau_row = tau_results[tau_results[\"id\"] == SAMPLE_ID]\n",
    "    if len(tau_row) > 0:\n",
    "        print(\"   ‚úÖ Found in tau_results\")\n",
    "        print(f\"   Columns: {list(tau_row.columns)}\")\n",
    "        print(f\"   D_eff: {tau_row.iloc[0].get('D_eff', 'MISSING')}\")\n",
    "        print(\n",
    "            f\"   porosity_measured: {tau_row.iloc[0].get('porosity_measured', 'MISSING')}\"\n",
    "        )\n",
    "        print(f\"   tau_factor: {tau_row.iloc[0].get('tau_factor', 'MISSING')}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå NOT found in tau_results\")\n",
    "\n",
    "    print(\"\\n2. PARQUET FILE:\")\n",
    "    parquet_file = PYBAMM_DIR / f\"results_rank_{SAMPLE_ID}.parquet\"\n",
    "    if parquet_file.exists():\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        print(f\"   ‚úÖ File exists\")\n",
    "        print(f\"   Total rows: {len(df)}\")\n",
    "        print(f\"   Param IDs: {sorted(df['param_id'].unique())}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå File does not exist\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae54a73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ No failures to visualize!\n"
     ]
    }
   ],
   "source": [
    "if len(df_failures) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    sample_counts = df_failures[\"sample_id\"].value_counts().sort_index()\n",
    "    axes[0, 0].bar(sample_counts.index, sample_counts.values)\n",
    "    axes[0, 0].set_title(\"Failures by Sample\")\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "    param_counts = df_failures[\"param_id\"].value_counts().sort_index()\n",
    "    axes[0, 1].bar(param_counts.index, param_counts.values)\n",
    "    axes[0, 1].set_title(\"Failures by Param ID\")\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "    reason_counts = df_failures[\"reason\"].value_counts()\n",
    "    axes[1, 0].barh(reason_counts.index, reason_counts.values)\n",
    "    axes[1, 0].set_title(\"Failures by Reason\")\n",
    "    axes[1, 0].grid(alpha=0.3, axis=\"x\")\n",
    "\n",
    "    failure_matrix = np.zeros((TOTAL_SAMPLES, PARAMS_PER_SAMPLE))\n",
    "    for _, r in df_failures.iterrows():\n",
    "        failure_matrix[r[\"sample_id\"], r[\"param_id\"]] = 1\n",
    "\n",
    "    im = axes[1, 1].imshow(\n",
    "        failure_matrix.T,\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"RdYlGn_r\",\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    plt.colorbar(im, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Failure Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n‚úÖ Visualization complete\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No failures to visualize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c85e7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking input feature availability across all parquet files...\n",
      "================================================================================\n",
      "\n",
      "Total rows checked: 6000\n",
      "\n",
      "Feature availability:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "input_SEI kinetic rate constant [m.s-1]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Electrolyte diffusivity [m2.s-1]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Initial concentration in electrolyte [mol.m-3]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Separator porosity:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Separator Bruggeman coefficient (electrolyte):\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Separator Bruggeman coefficient:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Positive particle radius [m]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Negative particle radius [m]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Positive electrode thickness [m]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "input_Negative electrode thickness [m]:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "bruggeman_derived:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "capacity_trend_ah:\n",
      "   Present: 6000 (100.0%)\n",
      "   NaN: 0 (0.0%)\n",
      "   Missing: 0 (0.0%)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Feature availability check complete\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Checking input feature availability across all parquet files...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "feature_availability = {\n",
    "    feat: {\"present\": 0, \"missing\": 0, \"nan\": 0} for feat in INPUT_FEATURES\n",
    "}\n",
    "feature_availability[\"bruggeman_derived\"] = {\"present\": 0, \"missing\": 0, \"nan\": 0}\n",
    "feature_availability[\"capacity_trend_ah\"] = {\"present\": 0, \"missing\": 0, \"nan\": 0}\n",
    "\n",
    "total_checked = 0\n",
    "\n",
    "for sample_id in range(TOTAL_SAMPLES):\n",
    "    parquet_file = PYBAMM_DIR / f\"results_rank_{sample_id}.parquet\"\n",
    "    if not parquet_file.exists():\n",
    "        continue\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        total_checked += 1\n",
    "\n",
    "        for feat in INPUT_FEATURES:\n",
    "            if feat in row.index:\n",
    "                if pd.isna(row[feat]):\n",
    "                    feature_availability[feat][\"nan\"] += 1\n",
    "                else:\n",
    "                    feature_availability[feat][\"present\"] += 1\n",
    "            else:\n",
    "                feature_availability[feat][\"missing\"] += 1\n",
    "\n",
    "        if \"bruggeman_derived\" in row.index:\n",
    "            if pd.isna(row[\"bruggeman_derived\"]):\n",
    "                feature_availability[\"bruggeman_derived\"][\"nan\"] += 1\n",
    "            else:\n",
    "                feature_availability[\"bruggeman_derived\"][\"present\"] += 1\n",
    "        else:\n",
    "            feature_availability[\"bruggeman_derived\"][\"missing\"] += 1\n",
    "\n",
    "        if \"capacity_trend_ah\" in row.index:\n",
    "            feature_availability[\"capacity_trend_ah\"][\"present\"] += 1\n",
    "        else:\n",
    "            feature_availability[\"capacity_trend_ah\"][\"missing\"] += 1\n",
    "\n",
    "print(f\"\\nTotal rows checked: {total_checked}\")\n",
    "print(\"\\nFeature availability:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feat, stats in feature_availability.items():\n",
    "    print(f\"\\n{feat}:\")\n",
    "    print(f\"   Present: {stats['present']} ({stats['present']/total_checked*100:.1f}%)\")\n",
    "    print(f\"   NaN: {stats['nan']} ({stats['nan']/total_checked*100:.1f}%)\")\n",
    "    print(f\"   Missing: {stats['missing']} ({stats['missing']/total_checked*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Feature availability check complete\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indiaai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
